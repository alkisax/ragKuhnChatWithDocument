/*
  ğŸ’¥Î— Î´Î¿Ï…Î»ÎµÎ¹Î¬ Ï„Î¿Ï… Ï†Î±ÎºÎ­Î»Î¿Ï… vectorize ÎµÎ¯Î½Î±Î¹ Î½Î± Ï€ÏÎ¿ÏƒÎ¸Î­ÏƒÎµÎ¹ vector ÏƒÏ„Î¿ field vector[] Ï„Ï‰Î½ mongo documents Î¼Î¿Ï… Î¼Î­ÏƒÎ¿ openAI.
  Î‘Ï…Ï„Î± Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Ï€Î¹Î± standalone scripts Î±Î»Î»Î± Î¼Î­ÏÎ¿Ï‚ Ï„Î¿Ï… ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¿Ï endpoint. ÎºÎ±Î¹ Î¿ Î»ÏŒÎ³Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿Ï„Î¹ Ï„Î¿ ÎµÏÏ‰Ï„Î·Î¼Î± Ï€Î¿Ï… Î¸Î± Î­ÏÏ‡ÎµÏ„Î±Î¹ Î±Ï€Î¿ Ï„Î¿ front Ï€ÏÎ­Ï€ÎµÎ¹ ÎºÎ±Î¹ Î±Ï…Ï„ÏŒ Î½Î± Î³Î¯Î½ÎµÎ¹ vectorise

  6ï¸âƒ£ ÎµÎ´Ï Î²ÏÎ¯ÏƒÎºÎ¿Î½Ï„Î±Î¹ 3 ÏƒÏ…Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚. Î— getEmbedding Ï€Î¿Ï… Î¼Î¿Ï… Î¼ÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ Î­Î½Î± ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÏƒÎµ vector. Î— cosineSimilarity ÎºÎ±Î¹ Î· semanticSearchParagraphs

  prev â†’ backend\src\paragraphs\paragraphMongoFeeder.script.ts
  next â†’ backend\src\vectorise\gptEmbedingsParagraph.controller.ts
*/

import axios from 'axios'
import Paragraph from '../paragraphs/paragraph.models'
import type { ParagraphType } from '../paragraphs/paragraph.types'

const OPENAI_API_KEY = process.env.OPENAI_API_KEY as string

/*
  ÎµÎ¾Î®Î³Î·ÏƒÎ· Ï„Î¿Ï…: return response.data.data[0].embedding

  Î‘Î½ ÏƒÏ„ÎµÎ¯Î»ÎµÎ¹Ï‚:
  {
    "model": "text-embedding-3-small",
    "input": "Mao Tse-tung thought"
  }

  Ï„ÏŒÏ„Îµ Ï„Î¿ API Î±Ï€Î±Î½Ï„Î¬ ÎºÎ¬Ï€Ï‰Ï‚ Î­Ï„ÏƒÎ¹:
  {
    "object": "list",
    "data": [
      {
        "object": "embedding",
        "index": 0,
        "embedding": [0.0123, -0.0456, 0.0789, ...] 
      }
    ],
    "model": "text-embedding-3-small",
    "usage": {
      "prompt_tokens": 5,
      "total_tokens": 5
    }
  }

  Î•Ï€Î¿Î¼Î­Î½Ï‰Ï‚...
  response.data
  ÎµÎ¯Î½Î±Î¹ ÏŒÎ»Î¿ Î±Ï…Ï„ÏŒ Ï„Î¿ JSON Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î¿.
  response.data.data
  ÎµÎ¯Î½Î±Î¹ Î¿ Ï€Î¯Î½Î±ÎºÎ±Ï‚ data: [ { â€¦ } ].
  response.data.data[0]
  ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Ï€ÏÏÏ„Î¿ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿ Ï„Î¿Ï… Ï€Î¯Î½Î±ÎºÎ± â€” Î´Î·Î»Î±Î´Î® Ï„Î¿ embedding Î³Î¹Î± Ï„Î¿ Ï€ÏÏÏ„Î¿ input.
  response.data.data[0].embedding
  ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ Î´Î¹Î¬Î½Ï…ÏƒÎ¼Î± Î±ÏÎ¹Î¸Î¼ÏÎ½ (number[]), Ï€Î¿Ï… Î¸Î­Î»ÎµÎ¹Ï‚ Î½Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ Mongo.
*/

// input: string | outpout: vector[]
const getEmbedding = async (text: string): Promise<number[]> => {
  const url = 'https://api.openai.com/v1/embeddings'
  const response = await axios.post(
    url,
    { model: 'text-embedding-3-small', input: text },
    {
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      }
    }
  )
  return response.data.data[0].embedding
}

// Î±Ï…Ï„ÏŒÏ‚ ÎµÎ¯Î½Î±Î¹ Î¿ Î¼Î±Î¸Î·Î¼Î±Ï„Î¹ÎºÏŒÏ‚ Ï„ÏÏ€Î¿Ï‚. Ï„Î¿ Ï€Î±Î¯ÏÎ½ÎµÎ¹Ï‚ Î±Ï€Î»Ï‰Ï‚ copy paste
const cosineSimilarity = (vecA: number[], vecB: number[]): number => {
  const dot = vecA.reduce((sum, a, i) => sum + a * vecB[i], 0)
  const normA = Math.sqrt(vecA.reduce((sum, a) => sum + a * a, 0))
  const normB = Math.sqrt(vecB.reduce((sum, b) => sum + b * b, 0))
  return dot / (normA * normB)
}

// input: Î· ÎµÏÏÏ„Î·ÏƒÎ· Î¼Î±Ï‚ ÎºÎ±Î¹ Ï€ÏŒÏƒÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ Î¸Î­Î»Î¿Ï…Î¼Îµ
export const semanticSearchParagraphs = async (query: string, topN = 5) => {

  // ÎºÎ¬Î½Î¿Ï…Î¼Îµ vector Ï„Î¿ ÎµÏÏÏ„Î·Î¼Î¬ Î¼Î±Ï‚
  const queryVector = await getEmbedding(query)

  // Fetch only fields we need
  const paragraphs = await Paragraph.find(
    { vectors: { $exists: true, $ne: [] } },
    { paragraphNo: 1, text: 1, vectors: 1 }
  ).lean<ParagraphType[]>()

  // remove junk before scoring
  // Î¼Î±Ï‚ Î­Î²Î³Î±Î¶Îµ Î»Î¬Î¸Î¿Ï‚ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î³Î¹Î±Ï„Î¯ Ï„Î¿ Parse Î´ÎµÎ½ ÎµÎ¯Ï‡Îµ Î³Î¯Î½ÎµÎ¹ ÎºÎ±Î»Î¬. ÎŒÏ€Ï‰Ï‚ "The Structure of Scientific Revolutions" "The Nature and Necessity of Scientific Revolutions" "Revolutions in science, 6-8, 92-98, 101-2" Ï€Î¿Ï… Î®Ï„Î±Î½ Ï„Î¯Ï„Î»Î¿Î¹ ÏƒÎµÎ»Î¹Î´ÏÎ½ Ï…Ï€Î¿ÏƒÎ·Î¼ÎµÎ¹ÏÏƒÎµÎ¹Ï‚ ÎºÎ»Ï€. Î“Î¹Î± Î±Ï…Ï„ÏŒ Ï€ÏÎ¹Î½ ÏƒÏ„Î®Î»Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î³ÏÎ¬Ï†Î¿Ï…Ï‚ Î³Î¹Î± ÏƒÏÎ³Î³ÏÎ¹ÏƒÎ· Ï€ÎµÏÎ½Î¬Î¼Îµ Î­Î½Î± Î±ÎºÏŒÎ¼Î± Ï†Î¯Î»Ï„ÏÎ¿
  const cleanParagraphs = paragraphs.filter(p =>
    p.text.length > 50 &&  //ÎºÏŒÎ²ÎµÎ¹ Ï€Î¿Î»Ï Î¼Î¹ÎºÏÎ¬ Î±Ï€Î¿ÏƒÏ€Î¬ÏƒÎ¼Î±Ï„Î±
    !/^\d+(\s|$)/.test(p.text) && // /^\d+(\s|$)/. ^ Î±ÏÏ‡Î® string â†’ Î¼ÎµÏ„Î¬ \d+ Î­Î½Î± Î® Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± ÏˆÎ·Ï†Î¯Î± â†’ Î¼ÎµÏ„Î¬ (\s|$) ÎµÎ¯Ï„Îµ ÎºÎµÎ½ÏŒ ÎµÎ¯Ï„Îµ Ï„Î­Î»Î¿Ï‚ Î³ÏÎ±Î¼Î¼Î®Ï‚. Î Î¹Î¬Î½ÎµÎ¹ Ï€ÏÎ¬Î³Î¼Î±Ï„Î± Ï„ÏÏ€Î¿Ï… '10', '42 ' Îº.Î»Ï€. (Ï€.Ï‡. Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚ ÏƒÎµÎ»Î¯Î´Ï‰Î½ ÏƒÏ„Î·Î½ Î±ÏÏ‡Î®).
    !/^(contents|index|references)/i.test(p.text) &&
    !/^(the\sstructure|the\sname|revolutions\s?in\s?science)/i.test(p.text)
  )

  // Î±Ï…Ï„ÏŒ Ï€Î¿Ï… Î¸Î± Î¼Î¿Ï… ÎµÏ€Î¹ÏƒÏ„ÏÎ±Ï†ÎµÎ¯ Ï„ÎµÎ»Î¹ÎºÎ¬ Î¸Î± ÎµÎ¯Î½Î±Î¹ Î­Î½Î± json obj Î¼Îµ { paragraphNo, text, score }
  const ranked = cleanParagraphs
    .map(p => ({
      paragraphNo: p.paragraphNo,
      text: p.text,
      score: cosineSimilarity(queryVector, p.vectors!)
    }))
    .sort((a, b) => b.score - a.score)

  // Only keep the 5 best
  return ranked.slice(0, topN)
}

export const gptEmbedingsService ={
  getEmbedding,
  cosineSimilarity,
  semanticSearchParagraphs
}
