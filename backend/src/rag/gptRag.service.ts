/*
  ğŸ”Ÿ routes

  prev â†’ backend\src\vectorise\gptEmbedingsParagraph.routes.ts
  next â†’ backend\src\rag\gptRagParagraph.controller.ts
*/

import axios from 'axios'

// input: string | output: string
// Î±Ï…Ï„Î® ÎµÎ´Ï ÎµÎ¯Î½Î±Î¹ Î· ÎºÎµÎ½Ï„ÏÎ¹ÎºÎ® ÏƒÏÎ½Î´ÎµÏƒÎ· Î³Î¹Î± Ï„Î¿Î½ gpt wraper. ÎšÎ¬Î½Î¿Ï…Î¼Îµ Î­Î½Î± post(url,parameters,auth) ÏŒÏ€Î¿Ï… Î¼Î­ÏƒÎ± ÏƒÏ„Î¿Ï…Ï‚ parameters Î²ÏÎ¯ÏƒÎºÎµÏ„Îµ Ï„Î¿ prompt Î¼Î¿Ï…. Î¤Î¿ prompt (Ï€Î¿Ï… ÏƒÏ„Î·Î½ rag Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ® Î¼Î±Ï‚ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ ÎºÎ±Î¹ Ï„Î¿ context Ï€Î¿Ï… Î­Ï‡ÎµÎ¹ Ï€ÏÎ¿ÎºÏÏˆÎµÎ¹ Î±Ï€Î¿ Ï„Î·Î½ cosine similarity search Ï„Î¿ Ï†Ï„Î¹Î¬Ï‡Î½Î¿Ï…Î¼Îµ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰) 
export const getGPTResponse = async (
  prompt: string,
  apiKey: string
): Promise<string> => {
  const url = 'https://api.openai.com/v1/chat/completions'

  try {
    const response = await axios.post(
      url,
      {
        model: 'gpt-3.5-turbo', 
        messages: [{ role: 'user', content: prompt }]
      },
      {
        headers: {
          Authorization: `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      }
    )

    // Î¼Î¿ÏÏ†Î® Ï„Î¿Ï… json response ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚
    return response.data.choices[0].message.content
  } catch (err: unknown) {
    const msg = err instanceof Error ? err.message : 'Unknown GPT error'
    throw new Error(`Error fetching GPT response: ${msg}`)
  }
}

/*
Î· ÎµÏ€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Ï„Î¿Ï… json response Î±Ï€Î¿ Ï„Î¿ openAi api ÎµÎ¯Î½Î±Î¹ Ï„Î·Ï‚ Î¼Î¿ÏÏ†Î®Ï‚

{
  "id": "chatcmpl-8XYZaBc123",
  "object": "chat.completion",
  "created": 1720000000,
  "model": "gpt-3.5-turbo",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "This is the AI's answer to your prompt."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 14,
    "completion_tokens": 8,
    "total_tokens": 22
  },
  "system_fingerprint": "fp_abc123"
}

Î³Î¹Î± Î±Ï…Ï„ÏŒ ÎºÏÎ±Ï„Î¬Î¼Îµ
return response.data.choices[0].message.content
*/
